{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answer5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushshah777/MachineLearningAssignment1/blob/master/Answer5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qNspLWfvZg_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import cv2\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "from scipy import ndimage\n",
        "from skimage import util\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras.layers import Input\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "rows = 28\n",
        "columns= 28\n",
        "dimension= rows*columns\n",
        "handcrafted_feature = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6u1y9hKuqFTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load mnist dataset so that we can find the connected components"
      ]
    },
    {
      "metadata": {
        "id": "-6zHbT_yaVjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6W8pn7U9qWlj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To convert grayscale images in 0 or 1 i.e black or white i used cv2 so the method cv2.threshold does is: if the pixel value is greater than the value passed in its parameter it will assign black or white image accordingly here i have selected 120 as pixel value\n"
      ]
    },
    {
      "metadata": {
        "id": "U3tEJdind77Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(x_train)):\n",
        "  img=x_train[i]\n",
        "  threshold=120\n",
        "  x_train[i]=cv2.threshold(img,threshold,255,cv2.THRESH_BINARY)[1]\n",
        "for i in range(len(x_test)):\n",
        "  img=x_train[i]\n",
        "  threshold=120\n",
        "  x_test[i]=cv2.threshold(img,threshold,255,cv2.THRESH_BINARY)[1]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tPvmP5ZceHz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train/255.0; #to normalize data\n",
        "x_train=x_train/255.0; #to normalize data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTZmOpELrWA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use the following code to visualize the image\n"
      ]
    },
    {
      "metadata": {
        "id": "YFWYj16Jb9K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c2bb7501-2712-429a-a626-08f0be704851"
      },
      "cell_type": "code",
      "source": [
        "visualize = 9\n",
        "index= -1\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == visualize:\n",
        "    index =i\n",
        "    break;\n",
        "inverted=(x_train[index])\n",
        "plt.grid(None)\n",
        "plt.imshow(inverted)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ad2f328d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEuAArEEKBBLgAKxBCgQS4CC/wuFfBKBqIQafwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MjyiTdpdrghz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We make vectors trainconnectedcomponents and testconnectedcomponents to hold the connected component data and then we use cipy.ndimage function to label it and get connected components\n"
      ]
    },
    {
      "metadata": {
        "id": "sgT2Lq6cfEbi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainconnectedcomponents=np.zeros_like(y_train)\n",
        "testconnectedcomponents=np.zeros_like(y_test)\n",
        "\n",
        "for i in range(len(trainconnectedcomponents)):\n",
        "  label,nearobjects=ndimage.label(util.invert(x_train[i]))\n",
        "  trainconnectedcomponents[i] = nearobjects\n",
        "for i in range(len(testconnectedcomponents)):\n",
        "  label, nearobjects=ndimage.label(util.invert(x_train[i]))\n",
        "  testconnectedcomponents[i]=nearobjects"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZW9u2C_MsNH6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preparing data and normalizing with flatenning data \n"
      ]
    },
    {
      "metadata": {
        "id": "kb5_OYQ5f5e5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format()=='channels_first':\n",
        "  x_train=x_train.reshape(x_train.shape[0],1,rows,columns)\n",
        "  x_test=x_test.reshape(x_test.shape[0],1,rows,columns)\n",
        "  inputvectorshape=(1,rows,columns)\n",
        "else:\n",
        "  x_train=x_train.reshape(x_train.shape[0],rows,columns,1)\n",
        "  x_test=x_test.reshape(x_test.shape[0],rows,columns,1)\n",
        "  inputvectorshape=(1,rows,columns)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UOs0i_i1fEYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train/ 255.0;\n",
        "x_test=x_test/ 255.0;\n",
        "\n",
        "\n",
        "trainconnectedcomponents=trainconnectedcomponents / 4\n",
        "testconnectedcomponents=testconnectedcomponents / 4\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZL0UgWThOE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train=keras.utils.to_categorical(y_train,10)\n",
        "y_test=keras.utils.to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-RW2u2yThu3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=x_train.reshape(x_train.shape[0],-1)\n",
        "x_test=x_test.reshape(x_test.shape[0],-1)\n",
        "y_train=y_train.T\n",
        "y_train=y_train.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Loi0jXIhsbSO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are 64 input neurons and has the activation function of sigmoid as we can just do 0 or 1 we do activation on input layer and then we add it with the hand crafted feature vector and then finally the output layer would be 10 neurons as always in this homework and then at the output layer we can use softmax which can recognize 10 classifiers and use that as activation function ."
      ]
    },
    {
      "metadata": {
        "id": "3Lf9CKhlh9dN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputvectorshape= Input((dimension,))\n",
        "featurevectorofconnectedcomponent= Input((handcrafted_feature,))\n",
        "imagevector = Dense(64, activation=\"sigmoid\")(inputvectorshape)\n",
        "outputmodel = layers.add([ imagevector, featurevectorofconnectedcomponent])\n",
        "outputmodel = Dense(10, activation=\"softmax\")(outputmodel)\n",
        "outputmodel = Model([inputvectorshape,featurevectorofconnectedcomponent], outputmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "paJTRDfQtCbe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use schocastic gradient descent optimizer to optimize the code"
      ]
    },
    {
      "metadata": {
        "id": "c84WXze-i_M5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "c8af4738-5fdd-48e1-d55f-543ee093d90d"
      },
      "cell_type": "code",
      "source": [
        "schocasticgradientdescent= optimizers.SGD(lr=0.1)\n",
        "outputmodel.compile(optimizer=schocasticgradientdescent, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "outputmodel.fit([x_train,trainconnectedcomponents], y_train, nb_epoch=10, batch_size=32)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.5666 - acc: 0.8513\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2932 - acc: 0.9161\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2458 - acc: 0.9289\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2135 - acc: 0.9386\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1906 - acc: 0.9453\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1725 - acc: 0.9504\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1576 - acc: 0.9548\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.1450 - acc: 0.9585\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.1350 - acc: 0.9615\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1261 - acc: 0.9639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ad3751080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "Pp-_HRbjjowL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ca6fdfa-a94e-475e-d6f0-4c294eadf807"
      },
      "cell_type": "code",
      "source": [
        "testresults=outputmodel.evaluate([x_test,testconnectedcomponents], y_test, verbose=0)\n",
        "print('Accuracy:', testresults[1]*100, '%')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 96.00999999999999 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
