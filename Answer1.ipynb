{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answer1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushshah777/MachineLearningAssignment1/blob/master/Answer1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Me58qUkW4i9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l44WbcKk5EGK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initialize(dimension): #initially the weight and bias are set to zero when the input is given to the neural network\n",
        "  weight=np.zeros(shape=(dimension,1))\n",
        "  bias=0\n",
        "  return weight, bias\n",
        "def activationsigmoid(x): #sigmoid is used as activation function here as we are interested to know if the input image is YES/NO belonging to a particular class (0-9)\n",
        "  return 1.0/(1.0+ np.exp(-x))\n",
        "def sigmoidprime(x): #sigmoid prime is used for calculating the derivatives of sigmoid function because at the output layer we have sigmoid as activation function so\n",
        "  return activationsigmoid(x)*(1-activationsigmoid(-x))\n",
        "def minibatches(X,Y,size): # used to calculate minibatches\n",
        "  for i in range(0,X.shape[0]-size+1,size):\n",
        "    a=slice(i,i+size)\n",
        "    yield X[a],Y[a]\n",
        "def mse(weight,bias,X,Y): # this is used to get the mean squared error which is nothing but the loss function of the neural network\n",
        "  sample=X.shape[1]\n",
        "  A=activationsigmoid(np.dot(weight.T,X)+bias)\n",
        "  cost=np.mean((Y-A) **2)\n",
        "  dweight= (1/sample) * np.dot(X, (2*(A-Y) * A *(1-A)).T) # formula as per discussed in class\n",
        "  dbias= (1/sample) * np.sum(2 * (A-Y) * A * (1-A))\n",
        "  gradients = {\"dweight\" : dweight, \"dbias\" : dbias}\n",
        "  cost= np.squeeze(cost)\n",
        "  return gradients, cost\n",
        "def backprop(weight,bias, X, Y, epochs, learningrate): #This function gives the method of backpropogation to  do gradiant descent\n",
        "  totalcost=[]\n",
        "  for i in range(epochs):\n",
        "    for b in minibatches(X.T,Y.T,32): # we calculate the mini batches by this function\n",
        "      x_batch, y_batch = b\n",
        "      gradients, cost = mse(weight, bias, x_batch.T, y_batch.T)\n",
        "      dweight=gradients[\"dweight\"]\n",
        "      dbias=gradients[\"dbias\"]\n",
        "      weight=dweight * (weight- learningrate)\n",
        "      bias= dbias * (bias - learningrate)\n",
        "    totalcost.append(cost)\n",
        "  weightbias={\"weight\": weight, \"bias\" : bias}\n",
        "  dweightdbias={\"dbias\": dbias, \"dweight\" : dweight}\n",
        "  return weightbias, dweightdbias, totalcost\n",
        "\n",
        "def prediction(weight, bias, X): #function to predict the values of image according to classifier\n",
        "  noofsamples=X.shape[1]\n",
        "  Y_pred=np.zeros((1, noofsamples))\n",
        "  weight= weight.reshape(X.shape[0], 1) # it contains confidence value which can be either 0 or 1 for 60000 images\n",
        "  A= activationsigmoid(np.dot(weight.T,X)+ bias)\n",
        "  for i in range(A.shape[1]):\n",
        "    if A[0,i] <=0.5:\n",
        "      Y_pred[0,i]=1\n",
        "    else:\n",
        "      Y_pred[0,i]=0\n",
        "  return Y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dz0F6eut5EDS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def networkarch(X_train,Y_train,X_test,Y_test,iterations=50, learningrate=0.3):\n",
        "  trainedmodels={}\n",
        "  categorical_train_y=Y_train;\n",
        "  categorical_test_y=Y_test;\n",
        "  categorical_train_y=keras.utils.to_categorical(categorical_train_y,10)  # we have 10 classes so we make categories of the label tests and train data\n",
        "  categorical_test_y=keras.utils.to_categorical(categorical_test_y,10)\n",
        "  \n",
        "  for i in range(0,10):\n",
        "    modelno=i\n",
        "    y_train_model=np.array(Y_train);\n",
        "    y_train_model=np.where(y_train_model == modelno, 1, 0) #we train the model to take either 0 or 1 (yes/no) value of y train and y test\n",
        "    \n",
        "    y_test_model=np.array(Y_test);\n",
        "    y_test_model=np.where(y_test_model == modelno, 1, 0)\n",
        "    \n",
        "    weight, bias=initialize(X_train.shape[0])\n",
        "    weightbias, dweightdbias, totalcost= backprop(weight, bias, X_train, y_train_model,iterations,learningrate)\n",
        "    weight=weightbias[\"weight\"]\n",
        "    bias= weightbias[\"bias\"]\n",
        "    \n",
        "    y_train_predicted=prediction(weight,bias,X_train) #we use weight, bias to predict the values of training input images \n",
        "    y_test_predicted=prediction(weight, bias, X_test)\n",
        "    \n",
        "    categorical_train_y[:,[i]] = y_train_predicted.T #storing indexes that are corrosponding to categorical data from y_train\n",
        "    categorical_test_y[:,[i]] = y_test_predicted.T\n",
        "    \n",
        "    trainaccuracy=np.mean(np.abs(y_train_predicted-y_train_model))\n",
        "    testaccuracy=np.mean(np.abs(y_test_predicted-y_test_model))\n",
        "    print(\" Classifier \"+ str(i) +\"s train accuracy is \"+str(trainaccuracy*100))\n",
        "    print(\"Classifier \"+ str(i) +\"s test accuracy is \"+str(testaccuracy*100))\n",
        "    d={\"Y_prediction_train\": y_train_predicted, \"Y_prediction_test\" : y_test_predicted, \"weight\": weight, \"bias\" : bias, \"totalcost\": totalcost,\"learningrate\": learningrate}\n",
        "    trainedmodels[i] = d\n",
        "  print(\"overall train accuracy is \"+str(np.mean(categorical_train_y-keras.utils.to_categorical(Y_train,10))* 100))\n",
        "  print(\"overall test accuracy is \"+str(np.mean(categorical_test_y-keras.utils.to_categorical(Y_test,10))* 100))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fX_ZeFF5EA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_test,y_test ) = mnist.load_data() # loading data from mnist dataset\n",
        "rows=28\n",
        "columns=28\n",
        "if K.image_data_format() == 'channels_first':          #checking if the data format is channel first, if so we add 1 before rows and columns.\n",
        "  x_train=x_train.reshape(x_train.shape[0],1,rows, columns)\n",
        "  x_test=x_test.reshape(x_test.shape[0],1,rows,columns)\n",
        "  inputshape=(1,rows,columns)\n",
        "else:\n",
        "  x_train=x_train.reshape(x_train.shape[0],rows,columns,1)\n",
        "  x_test=x_test.reshape(x_test.shape[0],rows,columns,1)\n",
        "  inputshape=(rows,columns,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHCpY5NLEB5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255.0     #normalizing the data\n",
        "x_test = x_test / 255.0\n",
        "x_train = x_train.reshape(x_train.shape[0], -1).T  #scaling the data to fit our neuralnetwork\n",
        "x_test = x_test.reshape(x_test.shape[0], -1).T\n",
        "y_test = y_test.T\n",
        "y_train = y_train.T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z5hC7YRM5D49",
        "colab_type": "code",
        "outputId": "1e50d921-439a-468a-d767-4263debaa797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "models = networkarch(x_train, y_train, x_test, y_test, iterations =12, learningrate= 0.1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Classifier 0s train accuracy is 90.12833333333333\n",
            "Classifier 0s test accuracy is 90.2\n",
            " Classifier 1s train accuracy is 88.76333333333334\n",
            "Classifier 1s test accuracy is 88.64999999999999\n",
            " Classifier 2s train accuracy is 90.07\n",
            "Classifier 2s test accuracy is 89.68\n",
            " Classifier 3s train accuracy is 89.78166666666667\n",
            "Classifier 3s test accuracy is 89.9\n",
            " Classifier 4s train accuracy is 90.26333333333334\n",
            "Classifier 4s test accuracy is 90.18\n",
            " Classifier 5s train accuracy is 90.96499999999999\n",
            "Classifier 5s test accuracy is 91.08000000000001\n",
            " Classifier 6s train accuracy is 90.13666666666667\n",
            "Classifier 6s test accuracy is 90.42\n",
            " Classifier 7s train accuracy is 89.55833333333332\n",
            "Classifier 7s test accuracy is 89.72\n",
            " Classifier 8s train accuracy is 90.24833333333333\n",
            "Classifier 8s test accuracy is 90.25999999999999\n",
            " Classifier 9s train accuracy is 90.08500000000001\n",
            "Classifier 9s test accuracy is 89.91\n",
            "overall train accuracy is 89.99999761581421\n",
            "overall test accuracy is 89.99999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}